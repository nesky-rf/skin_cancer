{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define VGG16 Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install ipykernel\n",
    "# setup python kernel to the virtual enviornment\n",
    "!python -m ipykernel install --user --name venv --display-name \"Python (venv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os, tempfile\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train, Validation and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "train_dir = './data_kaggle_train/'\n",
    "valid_dir = './data_kaggle_valid/'\n",
    "test_dir = './data_kaggle_test/'\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (224,224)\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "valid_gen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(train_dir, \n",
    "                                              batch_size=batch_size, \n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=True,\n",
    "                                              target_size=target_size)\n",
    "\n",
    "valid_generator = valid_gen.flow_from_directory(valid_dir, \n",
    "                                              batch_size=batch_size, \n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=False,\n",
    "                                              target_size=target_size)\n",
    "\n",
    "test_generator = test_gen.flow_from_directory(test_dir, \n",
    "                                              batch_size=1, \n",
    "                                              class_mode='binary',\n",
    "                                              shuffle=False,\n",
    "                                              target_size=target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives, BinaryAccuracy, Precision, Recall, AUC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "epochs = 50\n",
    "kernel_size = (3,3)\n",
    "pool_size = (2,2)\n",
    "input_shape = (224,224,3)\n",
    "n_filters = 32\n",
    "\n",
    "\n",
    "METRICS = [\n",
    "    TruePositives(name='tp'),\n",
    "    FalsePositives(name='fp'),\n",
    "    TrueNegatives(name='tn'),\n",
    "    FalseNegatives(name='fn'), \n",
    "    BinaryAccuracy(name='accuracy'),\n",
    "    Precision(name='precision'),\n",
    "    Recall(name='recall'),\n",
    "    AUC(name='auc'),\n",
    "    AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics= METRICS, output_bias= None, full_train= False):\n",
    "    # use VGG16\n",
    "    model= VGG16(weights='imagenet', include_top= False, input_shape= input_shape)\n",
    "    # define model to use on top of VGG16\n",
    "    if output_bias is not None:\n",
    "        output_bias = Constant(output_bias)\n",
    "    top_model = Sequential([\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "    ])\n",
    "    # build Model\n",
    "    model = Model(inputs= model.input, outputs= top_model(model.output))\n",
    "    # note that it is necessary to start with a fully-trained\n",
    "    # classifier, including the top classifier,\n",
    "    # in order to successfully do fine-tuning\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "    # set the first 25 layers (up to the last conv block) to non-trainable (weights will not be updated)\n",
    "    if(full_train == False):\n",
    "        for layer in model.layers[:25]:\n",
    "            layer.trainable = False\n",
    "    # compile Model options\n",
    "    model.compile(optimizer= SGD(lr=0.001, momentum= 0.9), loss= 'binary_crossentropy', metrics= metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Callbacks for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience=10, \n",
    "    restore_best_weights=True)\n",
    "# checkpoint to save model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"./models/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5\", \n",
    "    save_best_only=True, \n",
    "    save_weights_only=True)\n",
    "# reduce on plateau\n",
    "reduce_plateau = ReduceLROnPlateau(\n",
    "    min_lr=1e-7, \n",
    "    patience=5, \n",
    "    factor=0.5, \n",
    "    mode=\"min\", \n",
    "    monitor=\"val_loss\", \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = make_model(output_bias=inital_bias)\n",
    "# model.load_weights(initial_weights)\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "model = make_model(full_train=True)\n",
    "vgg16_history = model.fit(train_generator,\n",
    "                             steps_per_epoch = train_generator.samples // batch_size,\n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = valid_generator.samples // batch_size,\n",
    "                             epochs=epochs,\n",
    "                             callbacks=[early_stopping, checkpoint, reduce_plateau],\n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = input('Action: Save / Load / Check ')\n",
    "print('Action: ', action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_name = 'transfer'\n",
    "\n",
    "if(action == 'Save'):\n",
    "    print('Saving Model....')\n",
    "    model.save('./models/'+ model_name +'.h5')\n",
    "elif(action == 'Load'):\n",
    "    print('Loading Model...')\n",
    "    model = load_model('./models/'+ model_name +'.h5')\n",
    "elif(action == 'Check'):\n",
    "    print('Checking Model...')\n",
    "    reconstructed_model = load_model('./models/'+ model_name +'.h5')\n",
    "    np.testing.assert_allclose(\n",
    "        model.predict(test_generator,verbose=1), \n",
    "        reconstructed_model.predict(test_generator,verbose=1)\n",
    "    )\n",
    "else:\n",
    "    print('No Action')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                     color=colors[1], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(vgg16_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_vgg16 = model.predict(train_generator, batch_size=batch_size,verbose=1)\n",
    "valid_predictions_vgg16 = model.predict(valid_generator, batch_size=batch_size,verbose=1)\n",
    "test_predictions_vgg16 = model.predict(test_generator, batch_size=test_generator.samples, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    # show numbers\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax[0])\n",
    "    ax[0].set_title('Confusion matrix @{:.2f}'.format(p))\n",
    "    ax[0].set_ylabel('Actual label')\n",
    "    ax[0].set_xlabel('Predicted label')\n",
    "    # show %\n",
    "    cmp = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmp, annot=True, fmt=\".3f\", \n",
    "                xticklabels=[f\"pred_{c}\" for c in train_generator.class_indices], \n",
    "                yticklabels=[f\"true_{c}\" for c in train_generator.class_indices],\n",
    "                cmap=\"Blues\",\n",
    "                ax=ax[1])\n",
    "    ax[1].set_title('Confusion matrix @{:.2f}'.format(p))\n",
    "    ax[1].set_ylabel('Actual')\n",
    "    ax[1].set_xlabel('Predicted')\n",
    "\n",
    "    print('Legitimate Benign Detected (True Negatives): ', cm[0][0])\n",
    "    print('Fraudulent Benign Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Legitimate Malignant Detected (True Positives): ', cm[1][1])\n",
    "    print('Fraudulent Malignant Incorrectly Detected (False Negatives): ', cm[1][0])\n",
    "    print('Total Incorrectly Detected: ', np.sum(cm[0][1]+cm[1][0]),' out of ',np.sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_results = model.evaluate(valid_generator, steps=valid_generator.samples // batch_size, verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, vgg16_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "plot_confusion_matrix(test_generator.labels, test_predictions_vgg16, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = roc_curve(labels, predictions)\n",
    "    roc_auc = auc(fp, tp)\n",
    "    plt.plot(100*fp, 100*tp, label=name+' (area = %0.2f)' % roc_auc, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "#     plt.xlim([-0.5,20])\n",
    "#     plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(\"Train VGG16\", train_generator.labels, train_predictions_vgg16, color=colors[0])\n",
    "plot_roc(\"Validation VGG16\", valid_generator.labels, valid_predictions_vgg16, color=colors[1], linestyle='dotted')\n",
    "plot_roc(\"Test VGG16\", test_generator.labels, test_predictions_vgg16, color=colors[2], linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prc(\"Train VGG16\", train_generator.labels, train_predictions_vgg16, color=colors[0])\n",
    "plot_prc(\"Validation VGG16\", valid_generator.labels, valid_predictions_vgg16, color=colors[1], linestyle='dotted')\n",
    "plot_prc(\"Test VGG16\", test_generator.labels, test_predictions_vgg16, color=colors[2], linestyle='--')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def show_classification_report(labels, predictions, p=0.5, **kwargs):\n",
    "    print(classification_report(labels, predictions > p, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classification_report(test_generator.labels,test_predictions_vgg16,p=0.5,target_names=['benign','malignant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
